{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1e5d97-ac7f-4b49-9baa-9ff6d8a13195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b934f2c8-a578-4f09-b5bd-19852f0bd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, shape, weights=None):\n",
    "        self.shape = shape\n",
    "        self.num_layers = len(shape)\n",
    "        if weights is None:\n",
    "            self.weights = []\n",
    "            for i in range(self.num_layers - 1):\n",
    "                W = np.random.uniform(size=(self.shape[i + 1], self.shape[i] + 1))\n",
    "                self.weights.append(W)\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "    def run(self, data):\n",
    "        layer = data.T\n",
    "        for i in range(self.num_layers - 1):\n",
    "            prev_layer = layer\n",
    "            o = np.dot(self.weights[i], prev_layer)\n",
    "            # sigmoid\n",
    "            layer = scipy.special.expit(o)\n",
    "        return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9739c314-c284-424c-8af2-45e4f6aca4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result(object):\n",
    "    def __init__(self, best_particle, best_scores, accuracies, num_iterations):\n",
    "        self.best_particle = best_particle\n",
    "        self.best_scores = best_scores\n",
    "        self.accuracies = accuracies\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "def dim_weights(shape):\n",
    "    dim = 0\n",
    "    for i in range(len(shape) - 1):\n",
    "        dim = dim + (shape[i] + 1) * shape[i + 1]\n",
    "    return dim\n",
    "\n",
    "def eval_accuracy(weights, shape, X, y):\n",
    "    corrects, wrongs = 0, 0\n",
    "    nn = MultiLayerPerceptron(shape, weights=weights)\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        out_vector = nn.run(X[i])\n",
    "        y_pred = np.argmax(out_vector)\n",
    "        predictions.append(y_pred)\n",
    "        if y_pred == y[i]:\n",
    "            corrects += 1\n",
    "        else:\n",
    "            wrongs += 1\n",
    "    return corrects, wrongs, predictions\n",
    "\n",
    "def weights_to_vector(weights):\n",
    "    w = np.asarray([])\n",
    "    for i in range(len(weights) + 1):\n",
    "        v = weights[i].flatten()\n",
    "        w = np.append(w, v)\n",
    "    return w\n",
    "\n",
    "\n",
    "def vector_to_weights(vector, shape):\n",
    "    weights = []\n",
    "    idx = 0\n",
    "    for i in range(len(shape) - 1):\n",
    "        r = shape[i + 1]\n",
    "        c = shape[i]\n",
    "        idx_min = idx\n",
    "        idx_max = idx + r * c\n",
    "        W = vector[idx_min:idx_max].reshape((r, c))\n",
    "        weights.append(W)\n",
    "        idx = idx_max\n",
    "    return weights\n",
    "\n",
    "def eval_neural_network_via_vector(weights, shape, X, y):\n",
    "    mse = np.asarray([])\n",
    "    weight = vector_to_weights(np.array(weights), shape)\n",
    "    nn = MultiLayerPerceptron(shape, weights=weight)\n",
    "    y_pred = nn.run(X)\n",
    "    mse = np.append(mse, sklearn.metrics.mean_squared_error(np.atleast_2d(y), y_pred))\n",
    "    return mse\n",
    "\n",
    "def eval_neural_network_via_weights(weights, shape, X, y):\n",
    "    mse = np.asarray([])\n",
    "    for w in weights:\n",
    "        weight = vector_to_weights(w, shape)\n",
    "        nn = MultiLayerPerceptron(shape)\n",
    "        nn.weights = weight\n",
    "        y_pred = nn.run(X)\n",
    "        mse = np.append(mse, sklearn.metrics.mean_squared_error(np.atleast_2d(y), y_pred))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def print_best_particle(best_particle):\n",
    "    print(\"New best weights found at iteration #{i} with mean squared error: {score}\".format(i=best_particle[0], score=best_particle[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f9859e6-74a5-4980-818d-b74e450a90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import sklearn.metrics\n",
    "\n",
    "class MLPStochasticGradDescent:\n",
    "    def __init__(self, shape, learning_rate=0.1, max_epochs=1000, batch_size=1, print_epochs=True):\n",
    "        self.shape = shape\n",
    "        self.num_layers = len(shape)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.print_epochs = print_epochs\n",
    "        self.weights = []\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        self.weights = []\n",
    "        for i in range(self.num_layers - 1):\n",
    "            W = np.random.uniform(size=(self.shape[i + 1], self.shape[i]))\n",
    "            self.weights.append(W)\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(self.num_layers - 2):\n",
    "            activation = scipy.special.expit(np.dot(activations[-1], self.weights[i]))\n",
    "            activations.append(activation)\n",
    "\n",
    "        output = scipy.special.expit(np.dot(activations[-1], self.weights[-1].T))\n",
    "        activations.append(output)\n",
    "        return activations\n",
    "\n",
    "    def backward_propagation(self, X, y, activations):\n",
    "        error = activations[-1] - y\n",
    "        delta = error * activations[-1] * (1 - activations[-1])\n",
    "\n",
    "        for i in range(self.num_layers - 2, 0, -1):\n",
    "            self.weights[i] -= self.learning_rate * np.dot(delta.T, activations[i])\n",
    "            hidden_error = np.dot(delta, self.weights[i])\n",
    "            delta = hidden_error * activations[i] * (1 - activations[i])\n",
    "\n",
    "        self.weights[0] -= self.learning_rate * np.dot(delta.T, X)\n",
    "\n",
    "    def get_score(self, X, y):\n",
    "        nn = MultiLayerPerceptron(self.shape, weights=self.weights)\n",
    "        y_pred = nn.run(X)\n",
    "        mse = sklearn.metrics.mean_squared_error(y, y_pred.T)\n",
    "        return mse\n",
    "\n",
    "    def train(self, X, y_onehot, y):\n",
    "        self.initialize_weights()\n",
    "        i = 0\n",
    "        accuracies = []\n",
    "        best_scores = [(i, 1)]\n",
    "        if self.print_epochs:\n",
    "            print_best_particle([i, best_scores[-1]])\n",
    "        for epoch in range(self.max_epochs):\n",
    "            indices = np.random.permutation(X.shape[0])\n",
    "            X_shuffled = X[indices]\n",
    "            y_onehot_shuffled = y_onehot[indices]\n",
    "            for j in range(0, X.shape[0], self.batch_size):\n",
    "                X_batch = X_shuffled[j:j + self.batch_size]\n",
    "                y_batch = y_onehot_shuffled[j:j + self.batch_size]\n",
    "                activations = self.forward_propagation(X_batch)\n",
    "                self.backward_propagation(X_batch, y_batch, activations)\n",
    "                i += 1\n",
    "\n",
    "            score = self.get_score(X, y_onehot)\n",
    "            corrects, wrongs, predictions = eval_accuracy(self.weights, self.shape, X, y)\n",
    "            accuracy = corrects / (corrects + wrongs)\n",
    "            best_scores.append((i, score))\n",
    "            if self.print_epochs:\n",
    "                print_best_particle([i, best_scores[-1]])\n",
    "                print(\"With accuracy: {accuracy}\".format(accuracy=accuracy))\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        return Result(\n",
    "            best_particle=self.weights,\n",
    "            best_scores=best_scores,\n",
    "            accuracies=accuracies,\n",
    "            num_iterations=self.max_epochs\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations = self.forward_propagation(X)\n",
    "        return np.argmax(activations[-1], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a243d6fe-69ad-49c2-9d9a-9b9b82ea4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST digits from sklearn\n",
    "num_classes = 10\n",
    "mnist = sklearn.datasets.load_digits(n_class=num_classes)\n",
    "X, X_test, y, y_test = sklearn.model_selection.train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=42)\n",
    "\n",
    "num_inputs = X.shape[1]\n",
    "\n",
    "y_true = np.zeros((len(y), num_classes))\n",
    "for i in range(len(y)):\n",
    "    y_true[i, y[i]] = 1\n",
    "\n",
    "y_test_true = np.zeros((len(y_test), num_classes))\n",
    "for i in range(len(y_test)):\n",
    "    y_test_true[i, y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307a3e4-d0a2-4278-af9c-eda9622499e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = []\n",
    "# Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert target labels to one-hot encoding\n",
    "y_train_onehot = np.eye(num_classes)[y]\n",
    "\n",
    "# Define the MLP shape and hyperparameters\n",
    "mlp_shape = [X_train.shape[1], 64, num_classes]\n",
    "learning_rate = 0.01\n",
    "max_epochs = 1000\n",
    "print_epochs = False\n",
    "batch_size = 10\n",
    "\n",
    "# Instantiate and train the MLP\n",
    "mlp = MLPStochasticGradDescent(shape=mlp_shape, learning_rate=learning_rate,batch_size=batch_size, max_epochs=max_epochs, print_epochs=print_epochs)\n",
    "RESULTS.append([\"Gradient Descent\", mlp.train(X_train, y_train_onehot, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3110d-60af-492c-8844-728730324e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
